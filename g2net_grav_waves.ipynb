{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#IMPORTS\n\nimport numpy as np \nimport pandas\nimport math\n\nimport matplotlib.pyplot as plt\nimport os\nimport scipy\nfrom scipy import signal\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental.preprocessing import Resizing\nimport random\n\n!pip install -q nnAudio\nimport nnAudio\nfrom nnAudio.Spectrogram import CQT1992v2\nimport torch\n\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nimport librosa\nimport librosa.display\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-21T02:43:14.547085Z","iopub.execute_input":"2021-09-21T02:43:14.547368Z","iopub.status.idle":"2021-09-21T02:43:15.840066Z","shell.execute_reply.started":"2021-09-21T02:43:14.547341Z","shell.execute_reply":"2021-09-21T02:43:15.839171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#PREPROCESSING\n\n#Dictionary of data ID -> labels\nlabels_df = pandas.read_csv('../input/g2net-gravitational-wave-detection/training_labels.csv')\ndic = labels_df.set_index('id').to_dict()\nlabels = dic['target']\nprint(\"mean label: \",np.mean(np.array(list(labels.values()))))\nprint(len(labels.values()), \"total training data\")\n\n#Split list of data ID into train & validation\nid_data = list(labels.keys())\ndata_count = len(id_data)\ntrain_count = math.floor(data_count * .95)\nval_count = math.ceil(data_count * .05)\nassert(val_count + train_count == data_count)\nid_train = id_data[0:train_count]\nid_val   = id_data[train_count:data_count] \nrandom.shuffle(id_train)\nrandom.shuffle(id_val)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T02:45:11.23737Z","iopub.execute_input":"2021-09-21T02:45:11.23825Z","iopub.status.idle":"2021-09-21T02:45:11.244112Z","shell.execute_reply.started":"2021-09-21T02:45:11.238184Z","shell.execute_reply":"2021-09-21T02:45:11.243272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#DATA TRANSFORMATION METHODS\n\nwindow = signal.windows.tukey(4096)\n\ndef spec(waves,transform=CQT1992v2(sr=2048, hop_length=64, fmin=20, fmax=1024)): \n    #Windows sequential data -> normalizes -> converts to 3D freq. domain -> transpose\n    \n    waves = np.multiply(window,waves)\n    waves = np.hstack(waves)\n    waves = waves / np.max(waves)\n    waves = torch.from_numpy(waves).float()\n    image = transform(waves)\n    image = np.array(image)\n    image = np.transpose(image,(1,2,0))\n    return image\n\ndef id2path(idx,is_train=True):\n    #Takes data ID and returns file path locating numpy array\n    \n    path = '../input/g2net-gravitational-wave-detection'\n    if is_train:\n        path += '/train/'+idx[0]+'/'+idx[1]+'/'+idx[2]+'/'+idx+'.npy'\n    else:\n        path += '/test/'+idx[0]+'/'+idx[1]+'/'+idx[2]+'/'+idx+'.npy'\n    return path\n\ndef normalize(x, triple = True):\n    #Scale matrix of 3 vectors so each vector is in [-1,1]\n    #Currently not used, currently scaling all 3 by max of all 3\n    \n    if triple:\n        x0 = x[0] * 1/np.max(np.abs(x[0]))\n        x1 = x[1] * 1/np.max(np.abs(x[1]))\n        x2 = x[2] * 1/np.max(np.abs(x[2]))\n        return np.array([x0,x1,x2])\n    else:\n        return x * 1/np.max(np.abs(x))\n\n\nsos = signal.butter(8, [20,1000], 'bandpass', fs=2048, output='sos')\n\ndef bandpass(x):\n    #Windows sequential data -> filters out frequencies not in [20,1000]\n    \n    x[0] = np.multiply(window,x[0])\n    x[1] = np.multiply(window,x[1])\n    x[2] = np.multiply(window,x[2])\n    x[0] = signal.sosfilt(sos, x[0])\n    x[1] = signal.sosfilt(sos, x[1])\n    x[2] = signal.sosfilt(sos, x[2])\n    return x","metadata":{"execution":{"iopub.status.busy":"2021-09-21T02:52:06.837599Z","iopub.execute_input":"2021-09-21T02:52:06.837891Z","iopub.status.idle":"2021-09-21T02:52:06.848933Z","shell.execute_reply.started":"2021-09-21T02:52:06.837862Z","shell.execute_reply":"2021-09-21T02:52:06.84808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#GENERATORS\n\n#Generates 3D image data (spectrograms, frequency x intensity x time)\ndef generate_data(id_list=None, batch_size=32):\n    inputs      = []\n    targets     = []\n    batch_count = 0\n    \n    \n    random.shuffle(id_list)\n    \n    while True:\n        for idx in id_list:\n            inputs.append(spec(np.load(id2path(idx))))\n            targets.append(labels[idx])\n            batch_count += 1\n            if batch_count >= batch_size: \n                yield (np.array(inputs), np.array(targets))\n                inputs = []\n                targets = []\n                contexts = []\n                batch_count = 0\n             \n            \n\n#Generates 2D wave data (amplitude x time)\ndef generate_seq_data(id_list=None, batch_size=32):\n    inputs      = []\n    targets     = []\n    batch_count = 0\n    \n    random.shuffle(id_list)\n    \n    while True:\n        for idx in id_list:\n            seq = np.transpose(bandpass(np.load(id2path(idx))))\n            inputs.append(seq/np.max(seq))\n            targets.append(labels[idx])\n            batch_count += 1\n            if batch_count >= batch_size: \n                yield (np.array(inputs), np.array(targets))\n                inputs = []\n                targets = []\n                contexts = []\n                batch_count = 0","metadata":{"execution":{"iopub.status.busy":"2021-09-21T02:52:08.6305Z","iopub.execute_input":"2021-09-21T02:52:08.631389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Custom 1D ConvNet (Takes 1D Sequential data)\n\ninputs1 = layers.Input(shape=(4096,3))\nscale = 4\n#Large Filter\nlarge_conv1 = layers.Conv1D(filters=16*scale, kernel_size = 64, strides=5,  activation='relu')(inputs1)\nlarge_conv2 = layers.Conv1D(filters=32*scale, kernel_size = 32, strides=4,  activation='relu', dilation_rate=1)(large_conv1)\nlarge_conv3 = layers.Conv1D(filters=48*scale, kernel_size = 16, strides=1,  activation='relu', dilation_rate=2)(large_conv2)\nlarge_pool = layers.MaxPooling1D()(large_conv3)\n\n#Medium Filter\nmed_conv1 = layers.Conv1D(filters=16*scale, kernel_size = 16, strides=4, activation='relu')(inputs1)\nmed_conv2 = layers.Conv1D(filters=32*scale, kernel_size = 8, strides=2,  activation='relu', dilation_rate=1)(med_conv1)\nmed_conv3 = layers.Conv1D(filters=48*scale, kernel_size = 4, strides=1,  activation='relu', dilation_rate=2)(med_conv2)\nmed_pool = layers.MaxPooling1D()(med_conv3)\n\n#Small Filter\nsmall_conv1 = layers.Conv1D(filters=16*scale, kernel_size = 6, strides=2,  activation='relu')(inputs1)\nsmall_conv2 = layers.Conv1D(filters=32*scale, kernel_size = 4, strides=1,  activation='relu', dilation_rate=1)(small_conv1)\nsmall_conv3 = layers.Conv1D(filters=48*scale, kernel_size = 2, strides=1,  activation='relu', dilation_rate=2)(small_conv2)\nsmall_pool = layers.MaxPooling1D()(small_conv3)\n\n#Concatenate Filters\nconcat = layers.Concatenate(axis=1)([large_pool,med_pool,small_pool])\nreshape = layers.Reshape((1352,48*scale,1))(concat)\nconv2d = layers.Conv2D(filters=64, kernel_size=(16,16),strides=(8,8), activation='relu')(reshape)\npool = layers.GlobalMaxPool2D()(conv2d)\nflat = layers.Flatten()(pool)\ndense = layers.Dense(32, activation='relu')(flat)\ndrop = layers.Dropout(.5)(dense)\noutput = layers.Dense(1, activation='sigmoid')(drop)\nmodel1 = keras.Model(inputs1,output)\n\nmodel1.summary()\nopt = tf.keras.optimizers.Adam(\n    learning_rate=1e-4,\n)\n\nmodel1.compile(loss='binary_crossentropy', \n              optimizer=opt, \n              metrics=['accuracy','AUC'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Pretrained 2D ConvNet (Takes 3D image data)\n\n!pip install -U efficientnet\nimport efficientnet.keras as efn\n\ninputs = layers.Input(shape=(69,193,1))\nreshaped = layers.Conv2D(3,(3,3),padding='valid', activation='relu')(inputs) \n#preproc = preprocess_input(reshaped)\ninception = efn.EfficientNetB0(include_top=False,input_shape=())(reshaped)\nflat = layers.GlobalMaxPool2D()(inception)\ndrop = layers.Dropout(.5)(flat)\n#dense = layers.Dense(32, activation='relu')(drop)\noutputs = layers.Dense(1, activation='sigmoid')(drop)\nmodel2 = keras.Model(inputs, outputs)\n\nmodel2.summary()\n\nopt = tf.keras.optimizers.Adam(\n    learning_rate=.0001,\n)\n\nmodel2.compile(loss='binary_crossentropy', \n              optimizer='adam', \n              metrics=['accuracy','AUC'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Shuffle and instantiate data generators\n#In this case 1D\n\nrandom.shuffle(id_train)\nbatch_size = 256\ngenerator  = generate_seq_data(id_list = id_train,batch_size=batch_size)\ngenerator_val  = generate_seq_data(id_list = id_val,batch_size=batch_size)\ntrain_steps_per_epoch = train_count / batch_size\nval_steps   = 64#val_count / batch_size","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train\n\nmodel2.fit(generator,\n          validation_data=generator_val,\n          epochs=3,\n          steps_per_epoch = train_steps_per_epoch,\n          validation_steps = val_steps)\n\n#Current results are .75 AUC for model1 and .85 AUC for model2\n#Next step is to merge models into an ensemble, possibly train together. \n#Issue is 1d vs 2d conv require different learning rates. Pretrain then model3 = keras.Model([model1,model2],output)?\n#Can also just merge their prediction vectors","metadata":{},"execution_count":null,"outputs":[]}]}